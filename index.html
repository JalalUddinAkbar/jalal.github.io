<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jalal Uddin Akbar</title>
  
  <meta name="author" content="Jalal Uddin Akbar">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta charset="UTF-8">
  <meta property="og:site_name" content="Jalal Uddin Akbar" />
  <meta property="og:type" content="website"/>
  <meta property="og:title" content="Jalal Uddin Akbar"/>
  <meta property="og:url" content="https://jalal.github.io/"/>
  <meta property="og:description" content="PhD Student"/>
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="imgs/icon1.jpg">
</head>

<body id="Home">
  <header id="nav-wrapper">
    <!-- <nav class="navbar navbar-expand-md navbar-custom fixed-top bg-dark" id="Home" data-scroll-id="Home" tabindex="-1" style="outline: none;">
      <a href="#Home" class="nav-link active"><span class="nav-link-span"><span class="u-nav"><b>Home</b></span></span></a>
      <div class="collapse navbar-collapse" id="navbarToggle">
        <a href="#Research" class="nav-link"><span class="nav-link-span"><span class="u-nav"><b>Research</b></span></span></a>
        <a href="#News" class="nav-link"><span class="nav-link-span"><span class="u-nav"><b>News</b></span></span></a>
        <a href="#Publications" class="nav-link"><span class="nav-link-span"><span class="u-nav"><b>Publications</b></span></span></a>
        <a href="#Academic Service" class="nav-link"><span class="nav-link-span"><span class="u-nav"><b>Academic Service and Honor</b></span></span></a>
        <a href="#Volunteer" class="nav-link"><span class="nav-link-span"><span class="u-nav"><b>Volunteer Work</b></span></span></a>
        <a href="#Fun Facts" class="nav-link"><span class="nav-link-span"><span class="u-nav"><b>Fun facts about me!</b></span></span></a>
        <a href="#Contact" class="nav-link"><span class="nav-link-span"><span class="u-nav"><b>Contact</b></span></span></a>
      </div>
    </nav> -->
  </header>
  <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:7.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name><b>Jalal Uddin Akbar</b></name>
              </p>
              <heading>Hey! &#x1F60a</heading>
              <p>I received my MS from the 
                <a href="https://www.umpsa.edu.my/en/">Universiti Malaysia Pahang Al-Sultan Abdullah</a>, majoring in Soft Computing and Intelligent System. 
                 I was working in Intelligent System Lab with <a href="https://scholar.google.com/citations?user=AYEv07UAAAAJ&hl=en">Dr. Syafiq Fauzi Kamarulzaman</a> as a graduate research assistant throughout my master degree.
              </p>
              <p style="text-align:center">
              <p>
                I have spent a wonderful time at <a href="https://sites.google.com/view/jcchen/%E9%A6%96%E9%A0%81/">BIPI Lab</a> in 2024, where I worked with <a href="https://sites.google.com/view/jcchen/%E6%8C%87%E5%B0%8E%E6%95%99%E6%8E%88?authuser=0/">Prof. Jyh-Cheng Chen</a>.
              <font color="#F00"><strong><b>I am currently seeking a PhD position in Computer Science!</b></strong></font>
              <section id="Contact" style="padding-top: 80px; margin-top: -40px;">

                <a href="jalaluddinmdakbar00@gmail.com">Email</a> &nbsp/&nbsp
                <!-- <a href="mailto:wenqi.jia@gatech.edu">Email</a> &nbsp/&nbsp -->
                <a href="doc/CV_Jalal.pdf">CV</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=DZb_4WQAAAAJ&hl=en&authuser=1">Google Scholar</a> &nbsp/&nbsp
<!--                 <a href="https://twitter.com/Wenqi_Jia">Twitter</a> &nbsp/&nbsp -->
                <a href="https://github.com/JalalUddinAkbar">Github</a>  &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/jalal-uddin-akbar-deeplearning/">LinkedIn</a>
              </p>

              <font color="#F00"><strong><b>I'm looking for a PhD Position in Computer Science</u> and would love to join an exciting project! Please drop me an email if you think I'd be a good fit.🦉 </strong></font>
         
            </td>
            <td style="padding:3%;width:40%;max-width:40%;border-radius:100%; overflow:hidden;">
                <a href="imgs/new.png"><img style="width:80%;max-width:80%" alt="profile photo" src="imgs/new.png" class="hoverZoomLink"></a>
              </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle;">
              <section id="Research" style="padding-top: 80px; margin-top: -80px;">
              <heading><b>Research</b></heading>
              <p>
                <!-- My research interests lie in Computer Vision and Machine Learning. I'm particularly interested in hand-object interaction under the First-Person perspective and aim to leverage Egocentric Vision to model daily activities and social behaviors to help understand the interaction between humans and their surrounding world.                 My research interests lie in Computer Vision (CV), Video Analysis and Human-Computer Interaction (HCI). I’m particularly interested in hand-object interaction under the First-Person perspective, and aim to leverage Egocentric Vision to model daily activities and social behaviors to help build Human-Centric AI. -->
                <!-- My research lies at the intersection of Computer Vision and Machine Learning, with a focus on egocentric perception and predictive modeling of human behaviors. I aim to leverage multi-modal first-person signals — including visual, auditory, and motor cues — to understand and anticipate how humans interact with objects, people, and the environment, with the broader goal of enabling intelligent agents to perceive, reason, and act in human-centered, real-world scenarios. -->
                <b>
                  I am interested in 3D Computer Vision, Biomedical Image Analysis, and Human-Centric AI, with a focus on learning to reconstruct and interpret complex structures from visual and multimodal data. While I see strong opportunities in healthcare, I am equally motivated by fundamental vision challenges and broader applications of computer vision in domains such as robotics, environmental monitoring, and intelligent systems. <font color="#F00">Shoot me an email if you're interested in chatting or collaborating :)</font>
              </p>
                </b>
                <br>
<!--                 This has led me to explore how egocentric cues can be integrated with 3D human understanding and embodied systems, with potential applications in robotics and AR/VR. <font color="#F00">Shoot me an email if you're interested in chatting or collaborating :)</font> -->
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle;">
            <section id="News" style="padding-top: 80px; margin-top: -80px;">
            <heading><b>News</b></heading>
            <p>
              <b>02.2025</b>&nbsp&nbsp One paper accepted by CVPR '25! Check out the </div> <a href="">SocialGesture</a>!!🎉<br>
              <b>10.2024</b>&nbsp&nbsp One paper accepted by ECCV '24! Check out the </div> <a href="https://bolinlai.github.io/CSTS-EgoGazeAnticipation/">EgoGaze</a>!!🎉<br>
              <!-- <b></b>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&ensp; 🌽🌽🌽🌽🌽🌽🌽<br> -->
              <b>04.2024</b>&nbsp&nbsp Passed my Qualifier! I will transfer to UIUC in Fall 24. 🌽🌽🌽🧐🌽🌽🌽<br>
              <!-- <b></b>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&ensp; 🌽🌽🌽🌽🌽🌽🌽<br> -->
              <!-- <font color="#F00"><strong><b>02.2024</b>&nbsp&nbsp One paper accepted by CVPR '24! Check out the </div> <a href="https://vjwq.github.io/AV-CONV/">AV-CONV</a>!!</strong></font> 🎉🤹‍♀️<br> -->
              <b>02.2024</b>&nbsp&nbsp One paper accepted by CVPR '24! Check out the </div> <a href="https://vjwq.github.io/AV-CONV/">AV-CONV</a>!!🎉🤹‍♀️<br>
              <!-- <b>01.2023</b>&nbsp&nbsp I'll be interning at <a href="https://about.meta.com/realitylabs/">Meta Reality Labs</a> in summer 2023! ♾️👩‍💻<br> -->
              <!-- <b>10.2022</b>&nbsp&nbsp I attended ECCV 22 in person @ Tel-Aviv, Israel. Had so much fun in the Dead Sea! 🌊<br> -->
              <!-- <b>10.2022</b>&nbsp&nbsp I give a poster presentation at <a href="https://sites.google.com/view/egocentric-hand-body-activity">HBHA@ECCV22 workshop</a>, thanks for having me! 😊<br>
              <b>10.2022</b>&nbsp&nbsp I give a poster presentation at <a href="https://sites.google.com/view/hands2022/home?authuser=0">HANDS@ECCV22 workshop</a>, thanks for having me! 🤓<br>
              <b>09.2022</b>&nbsp&nbsp I give a poster presentation at <a href="https://ego4d-data.org/workshops/eccv22/">2nd International Ego4D Workshop@ECCV 2022</a>, thanks for having me! 🫡<br> -->
              <b>08.2022</b>&nbsp&nbsp One journal paper accepted by TNNLS! 🎉<br>
              <b>07.2022</b>&nbsp&nbsp One paper accepted by ECCV '22!! 🎉✡️<br>
              <!-- <b>06.2022</b>&nbsp&nbsp I attended CVPR 22 in person and got covid 😕 <br> -->
              <!-- <b>04.2022</b>&nbsp&nbsp I've accepted my CS PhD offer at Georgia Tech. 🐝🐝🐝 <br> -->
              <!-- <b>04.2022</b>&nbsp&nbsp Our <a href="https://ego4d-data.org/docs/challenge/">Ego4D challenges</a> are alive now! Come join us on the leaderboard! 🏆🚩<br> -->
              <b>03.2022</b>&nbsp&nbsp Our <a href="https://ego4d-data.org/">Ego4D</a> paper has been accepted by CVPR '22 as an oral paper! 🥂<br>
            </p>
          </td>
        </tr>
      </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <section id="Publications" style="padding-top: 80px; margin-top: -80px;">
              <heading><b>Publications</b></heading>
            </td>
          </tr>      
          <tr>
            <td style="padding:20px;width:40%;vertical-align:middle;">
              <div class="one">
                <img src='imgs/reviewaccess.jpg'width="200%">

              </div>
            </td>
            <td style="padding:20px;width:60%;vertical-align:middle;">
              <a href="https://ieeexplore.ieee.org/abstract/document/10379667">
                <papertitle>A Comprehensive Review on Deep Learning Assisted Computer Vision Techniques for Smart Greenhouse Agriculture</papertitle></a>
              <br>
              <strong>Jalal Uddin Md Akbar</strong>, 
              Syafiq Fauzi Kamarulzaman, Abu Jafar Md Muzahid, Md. Arafatur Rahman, Mueen Uddin
              <br>
              <em>IEEE Access</em>, 2024
              <br>
<!--               <a href="https://vjwq.github.io/VCR/"><font color="#ABB0B8">project</font></a> / -->
              <a href="https://ieeexplore.ieee.org/abstract/document/10379667">paper</a> /
              <a href=""><font color="#ABB0B8">code</font></a>

              <!-- <a href="https://github.com/BolinLai/CSTS">code<a> / 
              <a href="https://github.com/BolinLai/CSTS/tree/main/data">data Split</a> /
              <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/01396-supp.pdf">supplementary</a> /
              <a href="https://www.youtube.com/watch?v=5ApMaLhlxUc">video</a> /
              <a href="https://eccv2024.ecva.net/media/PosterPDFs/ECCV%202024/268.png?t=1726967693.823367">poster</a> -->
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:40%;vertical-align:middle;">
              <div class="one">
                <img src='imgs/yoloswin.png'width="120%">

              </div>
            </td>
            <td style="padding:20px;width:60%;vertical-align:middle;">
              <a href="https://thesai.org/Publications/ViewPaper?Volume=16&Issue=8&Code=IJACSA&SerialNo=97">
                <papertitle>YOLOv8s-Swin: Enhanced Tomato Ripeness Detection for Smart Agriculture</papertitle>
              </a>
              <br>
              <strong>Jalal Uddin Md Akbar</strong>, Syafiq Fauzi Kamarulzaman
<!--               <a href="https://bolinlai.github.io/">Bolin Lai</a>,
              <a href="https://fkryan.github.io/">Fiona Ryan</a>,
              <a href="https://sites.google.com/view/sangmin-lee">Sangmin Lee</a>,
              <a href="https://rehg.org/">James M. Rehg<sup>&dagger;</sup></a> -->
              <br>
              <em>International Journal of Advanced Computer Science and Applications(IJACSA)</em>, 2025
              <br>
			  <a href="https://thesai.org/Publications/ViewPaper?Volume=16&Issue=8&Code=IJACSA&SerialNo=97">paper</a> /
              <!-- <a href="https://bolinlai.github.io/CSTS-EgoGazeAnticipation/">project</a> / -->
<!--               <a href=""><font color="#ABB0B8">project</font></a> / 
              <a href=""><font color="#ABB0B8">arXiv</font></a> /  -->
			  <a href=""><font color="#ABB0B8">code</font></a> 
<!--               <a href="https://huggingface.co/datasets/IrohXu/SocialGesture">dataset</a>  -->
              <!-- <a href="">paper (coming soon)</a> -->
              <!-- <a href="https://github.com/BolinLai/CSTS">code<a> / 
              <a href="https://github.com/BolinLai/CSTS/tree/main/data">data Split</a> /
              <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/01396-supp.pdf">supplementary</a> /
              <a href="https://www.youtube.com/watch?v=5ApMaLhlxUc">video</a> /
              <a href="https://eccv2024.ecva.net/media/PosterPDFs/ECCV%202024/268.png?t=1726967693.823367">poster</a> -->
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:40%;vertical-align:middle;">
              <div class="one">
                <img src='imgs/plantstem.gif'width="120%">

              </div>
            </td>
            <td style="padding:20px;width:60%;vertical-align:middle;">
              <a href="https://ieeexplore.ieee.org/abstract/document/10307074">
                <papertitle>Plant Stem Disease Detection Using Machine Learning Approaches</papertitle>
              </a>
              <br>
			  <strong>Jalal Uddin Md Akbar</strong>, Syafiq Fauzi Kamarulzaman, Ekramul Haque Tusher 
<!--               <a href="https://bolinlai.github.io/">Bolin Lai</a>,
              <a href="https://fkryan.github.io/">Fiona Ryan</a>,
              <a href="https://aptx4869lm.github.io/">Miao Liu<sup>&dagger;</sup></a>,
              <a href="https://rehg.org/">James M. Rehg<sup>&dagger;</sup></a> -->
              <br>
              <em>International Conference on Computing and Networking Technology (ICCNT)</em>, 2023
              <br>
<!--               <a href="https://bolinlai.github.io/CSTS-EgoGazeAnticipation/">project</a> / -->
              <a href="https://ieeexplore.ieee.org/abstract/document/10307074">paper</a> /
<!--               <a href=""><font color="#ABB0B8">project</font></a> /  -->
<!--               <a href=""><font color="#ABB0B8">arXiv</font></a> /  -->
			  <a href=""><font color="#ABB0B8">code</font></a> 
<!--               <a href="https://github.com/BolinLai/CSTS/tree/main/data">data Split</a> /
              <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/01396-supp.pdf">supplementary</a> /
              <a href="https://www.youtube.com/watch?v=5ApMaLhlxUc">video</a> /
              <a href="https://eccv2024.ecva.net/media/PosterPDFs/ECCV%202024/268.png?t=1726967693.823367">poster</a> -->
            </td>
          </tr>
          <!-- <tr onmouseout="avconv_stop()" onmouseover="avconv_start()" bgcolor="#ffffd0"> -->
<!--           <tr onmouseout="avconv_stop()" onmouseover="avconv_start()">
              <td style="padding:25px;width:35%;vertical-align:middle;display:inline-block;">
  
              <div class="one">
                <div class="two" id='avconv'>
                  <video muted autoplay loop style="width:200%;vertical-align:middle;">
                    <source src="imgs/1035_slow.mp4" type="video/mp4">
                  </video>
                  <video muted autoplay loop style="width:200%;vertical-align:middle;">
                    <source src="imgs/825_slow.mp4" type="video/mp4">
                  </video>
                  </div>
                  <img src='imgs/avconv.png'width="130%" class="center">
                </div>
                <script type="text/javascript">
                  function avconv_start() {
                    document.getElementById('avconv').style.opacity = "1";
                  }
  
                  function avconv_stop() {
                    document.getElementById('avconv').style.opacity = "0";
                  }
                  avconv_stop()
                </script> -->
			<tr>
			<td style="padding:20px;width:40%;vertical-align:middle;">
              <div class="one">
                <img src='imgs/har.gif'width="200%">

              </div>
            </td>
            <td style="padding:20px;width:60%;vertical-align:middle;">
            </td>
              <a href="https://ieeexplore.ieee.org/abstract/document/9689891">
              <font color="#F00"></font> <papertitle>A deep Spatio-temporal network for vision-based sexual harassment detection</papertitle>
              </a>
              <br>
              Md Shamimul Islam, Md Mahedi Hasan, Sohaib Abdullah, <strong>Jalal Uddin Md Akbar</strong>, N H M Arafat, Saydul Akbar Murad
<!--          <a href="https://aptx4869lm.github.io/">Miao Liu</a>,
              <a href="https://www.hao-jiang.net/">Hao Jiang</a>,
              <a href="https://www.ishwarya.me/">Ishwarya Ananthabhotla</a>,
              <a href="https://rehg.org/">James Rehg<sup>&dagger;</sup></a>,<br>
              <a href="https://www.vamsiithapu.com/">Vamsi Krishna Ithapu<sup>&dagger;</sup></a>,
              <a href="https://ruohangao.github.io/">Ruohan Gao<sup>&dagger;</sup></a> -->
              <br>
              <em>Emerging Technology in Computing, Communication and Electronics (ETCCE)</em>, 2021
              <br>
<!--               <a href="https://vjwq.github.io/AV-CONV/">project</a> / -->
              <a href="https://ieeexplore.ieee.org/abstract/document/9689891">paper </a> /
<!--          <a href=""><font color="#ABB0B8">project</font></a> / 
              <a href=""><font color="#ABB0B8">arXiv</font></a> /  -->
			  <a href=""><font color="#ABB0B8">code</font></a> 
              <!-- <a href="TODO">paper </a> / -->
<!--          <a href="doc/CVPR2024.bib">bibtex</a> -->
<!--               <p><font color="#009A17"><em>(&#8656 Move your cursor on the image for a short demo video!)</em></font></p> -->
              <br>
              <p></p>
              <p>
              </p>
            </td>
          </tr>  

          <tr onmouseout="uflow_stop()" onmouseover="uflow_start()">
            <td style="padding:25px;width:35%;vertical-align:middle;display:inline-block;">
  
              <div class="one">
                  <img src='imgs/acl23.png'width="200%">
              </div>
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2110.07058">
                <papertitle>Werewolf Among Us: A Multimodal Dataset for Modeling Persuasion Behaviors in Social Deduction Games</papertitle>
              </a>
              <br>
              <a href="https://bolinlai.github.io/">Bolin Lai</a>,
              <a href="https://t.co/zOXcWW1aHS">Hongxin Zhang</a>,
              <a href="https://aptx4869lm.github.io/">Miao Liu</a>,
              <a>Aryan Pariani</a>,
              <a href="https://fkryan.github.io/">Fiona Ryan</a>,
              <br>
              <strong>Wenqi Jia</strong>, 
              <a href="https://rehg.org/">James Rehg<sup>&dagger;</sup></a>,
              <a href="https://cs.stanford.edu/~diyiy/">Diyi Yang<sup>&dagger;</sup></a>
              <br>
              <em>ACL Findings</em>, 2023 
              <br>
              <a href="https://persuasion-deductiongame.socialai-data.org">project</a> /
              <a href="https://aps.arxiv.org/pdf/2212.08279">paper</a> /
              <a href="doc/ACL2023.bib">bibtex</a>
              <br>
              <p></p>
              <p>
              </p>
            </td>
          </tr>     
          <!-- <tr onmouseout="uflow_stop()" onmouseover="uflow_start()">
            <td style="padding:25px;width:35%;vertical-align:middle;display:inline-block;">
  
              <div class="one">
                  <img src='imgs/ego4d.png'width="180%">
              </div>
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <a href="">
                <papertitle>Ego4D: Around the World in 3,000 Hours of Egocentric Video</papertitle>
              </a>
              <br>
              <a href="">Kristen Grauman</a>, et al.
              <br>
              <em>T-PAMI</em>, 2023 &nbsp <font color=#FF8080><strong>(Special Issue on Best of CVPR 2022)</strong></font> (under review)
              <br>
              <a href="">project</a> /
              <a href="">paper</a> /
              <a href="">bibtex</a>
              <br>
              <p></p>
              <p>
              </p>
            </td>
          </tr>  -->
          <!-- <tr onmouseout="mip360_stop()" onmouseover="mip360_start()" bgcolor="#ffffd0"> -->
          <!-- <tr onmouseout="mip360_stop()" onmouseover="mip360_start()" bgcolor="#ffffd0"> -->
          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()">
              <td style="padding:25px;width:35%;vertical-align:middle;display:inline-block;">
              <div class="one">
                <div class="two" id='mip360_image'>
                <video muted autoplay loop style="width:200%;vertical-align:middle;">
                  <!-- <source src="imgs/11105.mp4" type="video/mp4"> -->
                  <source src="imgs/demo.mp4" type="video/mp4">
                </video>
                </div>
                <img src='imgs/egogan.png' width="200%">
              </div>
              <script type="text/javascript">
                function mip360_start() {
                  document.getElementById('mip360_image').style.opacity = "1";
                }

                function mip360_stop() {
                  document.getElementById('mip360_image').style.opacity = "0";
                }
                mip360_stop()
              </script>
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2203.11305">
                <papertitle><font color="#1772d0">Generative Adversarial Network for Future Hand Segmentation from Egocentric Video</font></papertitle>
              </a>
              <br>
              <strong>Wenqi Jia</strong>,
              <a href="https://aptx4869lm.github.io/">Miao Liu</a>,
              <a href="https://rehg.org/">James Rehg<sup>&dagger;</sup></a>
              <br>
							<em>ECCV</em>, 2022
              <br>
              <a href="https://vjwq.github.io/EgoGAN/">project</a> /
              <a href="https://vjwq.github.io/EgoGAN/assets/EgoGAN.pdf">paper</a>&nbsp/&nbsp 
              <a href="https://github.com/VJWQ/EgoGAN.git">code</a>&nbsp/&nbsp 
              <a href="https://vjwq.github.io/EgoGAN/assets/EgoGAN-supp.pdf">supplement</a> /
              <a href="https://vjwq.github.io/EgoGAN/assets/EgoGAN_poster.pdf">poster</a> /
              <a href="https://vjwq.github.io/EgoGAN/assets/EgoGAN_video.mp4">video</a>&nbsp/&nbsp 
              <!-- <a href="https://youtu.be/zBSH-k9GbV4">video</a> -->
              <a href="doc/ECCV2022.bib">bibtex</a>
              <!-- <p><font color="#FF8080"><em>(&#8656 Move your cursor on the image for a short demo video!)</em></font></p> -->
              <p><font color="#009A17"><em>(&#8656 Move your cursor on the image for a short demo video!)</em></font></p>
              <p></p>
            </td>
          </tr> 

          <tr onmouseout="uflow_stop()" onmouseover="uflow_start()">
            <td style="padding:25px;width:35%;vertical-align:middle;display:inline-block;">

              <div class="one">
                  <img src='imgs/ego4d.png'width="180%">
              </div>
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2110.07058">
                <papertitle>Ego4D: Around the World in 3,000 Hours of Egocentric Video</papertitle>
              </a>
              <br>
              <a href="https://www.cs.utexas.edu/users/grauman/">Kristen Grauman</a>, et al.
              <br>
              <em>CVPR</em>, 2022 &nbsp <font color=#FF8080><strong>(Oral)</strong></font>
              <!-- <em>ECCV</em>, 2020 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
              <br>
              <a href="https://ego4d-data.org/">project</a> /
              <a href="https://arxiv.org/pdf/2110.07058.pdf">paper</a> /
              <a href="https://github.com/EGO4D">code</a> /
              <a href="https://ego4d-data.org/#download">dataset</a> /
              <a href="https://drive.google.com/file/d/1oknfQIH9w1rXy6I1j5eUE6Cqh96UwZ4L/view?usp=sharing">video</a> /
              <a href="doc/Ego4D.bib">bibtex</a>
              <br>
              <p></p>
              <p>
              </p>
            </td>
          </tr>  

          <tr onmouseout="thresh_stop()" onmouseover="thresh_start()">
            <td style="padding:25px;width:35%;vertical-align:middle;display:inline-block;">
              <div class="one">
                <div class="two" id='thresh_image'>
                  <img src='imgs/ijcv1.png' width="200%"></div>
                  <img src='imgs/ijcv1.png' width="200%">
              </div>
              <script type="text/javascript">
                function thresh_start() {
                  document.getElementById('thresh_image').style.opacity = "1";
                }

                function thresh_stop() {
                  document.getElementById('thresh_image').style.opacity = "0";
                }
                thresh_stop()
              </script>
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <!-- <a href="https://arxiv.org/abs/2007.07350"> -->
                <papertitle>Paying More Attention to Motion:
                  Attention Distillation for Learning Video Representations</papertitle>
              <!-- </a> -->
              <br>
              <a href="https://aptx4869lm.github.io/">Miao Liu</a>,
              <strong>Wenqi Jia</strong>,
              <a>Xin Chen</a>,
              <a>Yun Zhang</a>,
              <a href="https://www.biostat.wisc.edu/~yli/">Yin Li</a>,
              <a href="https://rehg.org/">James Rehg<sup>&dagger;</sup></a>
              <br>
              <em>IJCV</em>, 2021 &nbsp <font color=#FF8080><strong>(Special Issue)</strong></font> (under review)
              <br>
              <a><font color="#ABB0B8">arXiv</font></a> /
              <a><font color="#ABB0B8">code</font></a> /
              <a><font color="#ABB0B8">bibtex</font></a>
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:35%;vertical-align:middle">
              <div><img src="imgs/tip.png" width="100%"></div>
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/9887964">
                <papertitle><font color="#1772d0">Holistic-Guided Disentangled Learning With Cross-Video Semantics Mining for Concurrent 
                  First-Person and Third-Person Activity Recognition</font></papertitle>
              </a>
              <br>
              <a>Tianshan Liu</a>,
              <strong>Wenqi Jia</strong>, 
              <a>Rui Zhao</a>,
              <a href="http://www.eie.polyu.edu.hk/~enkmlam/">Kin-Man Lam<sup>&dagger;</sup></a>,
              <a>Jun Kong</a>
              <br>
							<em>TNNLS</em>, 2022
              <br>
              <a href="https://ieeexplore.ieee.org/document/9887964">paper</a> / 
              <!-- <a><font color="#ABB0B8">code</font></a> /
              <a><font color="#ABB0B8">dataset</a> / -->
              <a href="doc/TNNLS2022.bib">bibtex</a>
              </td>
          </tr>
<!-- 
          <tr onmouseout="loss_stop()" onmouseover="loss_start()">
            <td style="padding:20px;width:35%;vertical-align:middle">
              <div class="one" style="display:inline-block;">
                <img src='imgs/icassp.png' width="200%">
              </div>
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/9413846">
                <papertitle>Feature Redundancy Mining: Deep Light-Weight Image Super-Resolution Model</papertitle>
              </a>
              <br>
              <a href="https://gwansiu.com/">Jun Xiao</a>,
              <strong>Wenqi Jia</strong>,
              <a href="http://www.eie.polyu.edu.hk/~enkmlam/">Kin-Man Lam<sup>&dagger;</sup></a>
              <br>
              <em>ICASSP</em>, 2021 
              <br>
              <a href="https://ieeexplore.ieee.org/document/9413846">paper</a> / 
              <a href="doc/ICASSP2021.bib">bibtex</a>
              <p></p>
            </td>
          </tr>

          <tr onmouseout="mpi_stop()" onmouseover="mpi_start()">
            <td style="padding:20px;width:35%;vertical-align:middle">
              <div class="one">
                <img src='imgs/icip.png' width="200%">
              </div>
              <script type="text/javascript">
                function mpi_start() {
                  document.getElementById('mpi_image').style.opacity = "1";
                }

                function mpi_stop() {
                  document.getElementById('mpi_image').style.opacity = "0";
                }
                mpi_stop()
              </script>
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/8803251">
                <papertitle>Deep progressive convolutional neural network for blind super-resolution with multiple degradations</papertitle>
              </a>
              <br>
              <a href="https://gwansiu.com/">Jun Xiao</a>,
              <a>Rui Zhao</a>,
              <a>Shun-Cheung Lai</a>,
              <strong>Wenqi Jia</strong>,
              <a href="http://www.eie.polyu.edu.hk/~enkmlam/">Kin-Man Lam<sup>&dagger;</sup></a>
              <br>
              <em>ICIP</em>, 2019
              <br>
              <a href="https://ieeexplore.ieee.org/document/8803251">paper</a> / 
              <a href="doc/ICIP2019.bib">bibtex</a>
              <p></p>
              <p>View extrapolation with multiplane images works better if you reason about disocclusions and disparity sampling frequencies.</p>
            </td>
          </tr> -->

        </tbody></table>

          <!-- <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cs188.jpg" alt="cs188">
            </td>
            <td width="75%" valign="center">
              <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
              <br>
              <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
              <br>
              <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
            </td>
          </tr> -->
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <section id="Academic Service" style="padding-top: 80px; margin-top: -80px;">
                <heading><b>Academic Service and Volunteer Work</b></heading>
                <ul>
                  <!-- <li><b>Talk</b> 🎤, HANDS@ECCV22 workshop, 2nd International Ego4D Workshop@ECCV 2022</li> -->
                  <li><b>Reviewer</b> 🔎, CVPR, ECCV, BMVC, ICCV </li>
                  <li><b>Certified First Responder</b> 🚑, Hong Kong Red Cross, Jun 2015 - Jun 2019</li>
                  <!-- <li><b>First Runner Up</b> 🥈, IEEE Video and Image Processing Cup (VIP Cup) 2017</li> -->
                </ul>
              </td>
            </tr>
          </tbody></table>

          <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <section id="Volunteer" style="padding-top: 80px; margin-top: -80px;">
                <heading><b>Volunteer Work</b></heading>
                <ul>
                  <li><b>Certified First Responder</b> 🚑, Hong Kong Red Cross, Jun 2015 - Jun 2019</li>
                  <li><b>General Secretary</b> 🤹‍♀️, Exploring Hong Kong Community (EHKC), Jan 2017 - Jan 2018</li>
                  <li><b>International Volunteer</b> 🤝, Service Learning Project in Cambodia, Jun 2016</li>
                </ul>
              </td>
            </tr>
          </tbody></table> -->
        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
            <heading>Academic Service</heading></td><br>

            <td width="75%" valign="center">
              <p>Reviewer, CVPR 2022</p>
              <br>
          </tr>
        </tbody></table> -->
        <!-- <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            <td width="75%" valign="center">
              <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
              <br>
              <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member, CVPR 2021</a>
              <br>
              <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
              <br>
              <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
            </td>
          </tr> -->
          <!-- <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cs188.jpg" alt="cs188">
            </td>
            <td width="75%" valign="center">
              <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
              <br>
              <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
              <br>
              <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
            </td>
          </tr> -->
        <!-- </tbody></table> -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <section id="Fun Facts" style="padding-top: 80px; margin-top: -80px;">
              <heading><b>Fun facts about me!</b></heading>
              <ul>
              <li>Obviously I love travelling around the world: 🐱‍🚀 </li>
              <p>
                <!-- <a href="https://flagpedia.net/"><img src="country/cn.png" width="30" height="30" style="float:left"></a> -->
                <img src="country/cn.png" width="30" height="30" style="float:left">
                <img src="country/hk.png" width="30" height="30" style="float:left">
                <img src="country/mo.png" width="30" height="30" style="float:left">
                <img src="country/us.png" width="30" height="30" style="float:left">
                <img src="country/kh.png" width="30" height="30" style="float:left">
                <img src="country/sg.png" width="30" height="30" style="float:left">
                <img src="country/my.png" width="30" height="30" style="float:left">
                <img src="country/au.png" width="30" height="30" style="float:left">
                <img src="country/fr.png" width="30" height="30" style="float:left">
                <img src="country/lu.png" width="30" height="30" style="float:left">
                <img src="country/dk.png" width="30" height="30" style="float:left">
                <img src="country/no.png" width="30" height="30" style="float:left">
                <img src="country/is.png" width="30" height="30" style="float:left">
                <img src="country/se.png" width="30" height="30" style="float:left">
                <img src="country/fi.png" width="30" height="30" style="float:left">
                <img src="country/pl.png" width="30" height="30" style="float:left">
                <img src="country/de.png" width="30" height="30" style="float:left">
                <img src="country/be.png" width="30" height="30" style="float:left">
                <img src="country/es.png" width="30" height="30" style="float:left">
                <img src="country/il.png" width="30" height="30" style="float:left">
                <img src="country/qa.png" width="30" height="30" style="float:left">
                <img src="country/ca.png" width="30" height="30" style="float:left">
              </p><br><br> 
              <!-- <li>I'm <b>Chinese</b> and if you wonder what's the correct pronunciation of my name (with the tones!), try to say the brand "<a href="https://www.google.com/search?q=givenchy+pronunciation+in+british+english">Givenchy</a>"in British accent 🤣</li> -->
              <li>I play the <b>piano</b> 🎹 & very into classical music. </li>
              <li>I'm a <b>J-Rock fan</b>! Read my article on the fascinating cultural phenomenon <a href="https://en.wikipedia.org/wiki/Visual_kei">Visual Kei</a>: <a href="doc/MUS518_Final_Paper_Wenqi.pdf"><em>Staging Cultural Fusion and Gender Performativity</em></a>.</li
              <li>I love <b>Renaissance</b> art and <b>Surrealism</b>! During the pandemic I was admitted as a <a href="https://arthistory.hku.hk/index.php/academic-programmes/master-of-arts-in-art-history/">Master of Arts in Art History</a> at the <a href="https://www.hku.hk/">University of Hong Kong</a> (but didn't enrol cause I decided to be focused on my passion in Computer Science first 👩‍💻)</li>
              <!-- <li>I learned my <b>Japanese</b> through Anime (<a href="https://www.netflix.com/title/70205012">NARUTO</a> is my favorite 🔥)</li> -->
              <!-- <li>Je parle un peu <b>français</b> (a beginner who likes to say Je ne sais pas) 🧐 </li> -->
              </ul>
            </td>
          </tr>
        </tbody></table>
        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Misc.</heading>
            </td>
          </tr>
        </tbody></table> -->
      </td>
    </tr>
  </table>

  <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=100&t=n&d=thMjNOKpOYN-BfENEOsmSjlm2NasTlRcMWsyqX5vW1I&co=2d78ad&ct=ffffff&cmo=3acc3a&cmn=ff5353'></script>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-XDES9G4ED2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-XDES9G4ED2');
  </script>
</body>

</html>
